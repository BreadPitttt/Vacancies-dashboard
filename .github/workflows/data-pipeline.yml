name: Data Pipeline

on:
  workflow_dispatch: {}
  schedule:
    - cron: '15 18 * * *'
    - cron: '30 20 * * 0'

permissions:
  contents: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false

jobs:
  scrape-and-validate:
    timeout-minutes: ${{ github.event.schedule == '30 20 * * 0' && 240 || 120 }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python and cache dependencies
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run scraper
        env:
          PYTHONUNBUFFERED: "1"
          TELEGRAM_RSS_BASE: ${{ vars.TELEGRAM_RSS_BASE }}
          IS_HARD_RECHECK: ${{ github.event.schedule == '30 20 * * 0' }}
          # Tunable knobs (safe defaults are in code; override here if needed)
          MAX_WORKERS: ${{ vars.MAX_WORKERS }}
          PER_SOURCE_MAX: ${{ vars.PER_SOURCE_MAX }}
          CONNECT_TIMEOUT: ${{ vars.CONNECT_TIMEOUT }}
          READ_TIMEOUT: ${{ vars.READ_TIMEOUT }}
          RETRY_TOTAL: ${{ vars.RETRY_TOTAL }}
          RETRY_CONNECT: ${{ vars.RETRY_CONNECT }}
          RETRY_READ: ${{ vars.RETRY_READ }}
          BACKOFF_FACTOR: ${{ vars.BACKOFF_FACTOR }}
          MAX_BACKOFF_SECONDS: ${{ vars.MAX_BACKOFF_SECONDS }}
          PER_HOST_RPM: ${{ vars.PER_HOST_RPM }}
          BASELINE_SLEEP_S: ${{ vars.BASELINE_SLEEP_S }}
          JITTER_MIN: ${{ vars.JITTER_MIN }}
          JITTER_MAX: ${{ vars.JITTER_MAX }}
          CB_FAILURE_THRESHOLD: ${{ vars.CB_FAILURE_THRESHOLD }}
          CB_OPEN_SECONDS: ${{ vars.CB_OPEN_SECONDS }}
          CB_HALF_OPEN_PROBE: ${{ vars.CB_HALF_OPEN_PROBE }}
        run: python scraper.py

      - name: Validate JSON Schema
        run: python validate.py

      - name: Quality checks (links, dates, dups)
        run: python qc_checks.py

      - name: Generate and Format Data Files
        run: |
          python - << 'PY'
          import json, datetime, pathlib
          data_path = pathlib.Path("data.json")
          health_path = pathlib.Path("health.json")
          data = json.loads(data_path.read_text(encoding="utf-8"))
          ti = data.get("transparencyInfo", {})
          health = {"ok": True, "checkedAt": datetime.datetime.utcnow().isoformat() + "Z", **ti}
          health_path.write_text(json.dumps(health, indent=2, ensure_ascii=False), encoding="utf-8")
          data_path.write_text(json.dumps(data, indent=2, ensure_ascii=False), encoding="utf-8")
          PY

      - name: Commit and Push Changes
        run: |
          set -e
          git config user.name "GitHub Actions Bot"
          git config user.email "actions-bot@users.noreply.github.com"
          if ! git diff --quiet data.json health.json; then
            git add data.json health.json
            COMMIT_MSG="chore(data): Nightly data refresh"
            if [ "${{ github.event.schedule }}" = "30 20 * * 0" ]; then
              COMMIT_MSG="chore(data): Weekly hard recheck"
            fi
            git commit -m "$COMMIT_MSG"
            git pull --rebase
            git push
          else
            echo "No data changes to commit."
          fi

  lighthouse:
    runs-on: ubuntu-latest
    needs: scrape-and-validate
    if: ${{ github.event_name != 'workflow_dispatch' && vars.PAGES_URL != '' }}
    steps:
      - name: Audit homepage with Lighthouse CI
        uses: treosh/lighthouse-ci-action@v12
        with:
          urls: |
            ${{ vars.PAGES_URL }}
          budgetPath: ./.github/lighthouse/budget.json
          uploadArtifacts: true
      - name: Check health.json endpoint
        run: |
          base_url="${{ vars.PAGES_URL }}"
          health_url="$base_url/health.json"
          http_code=$(curl -s -o /dev/null -w "%{http_code}" "$health_url")
          if [ "$http_code" -ne 200 ]; then
            echo "Error: health.json is not accessible (HTTP $http_code)"
            exit 1
          fi
          echo "health.json is available online (HTTP 200)."
