name: Nightly Recheck

on:
  workflow_dispatch: {}
  schedule:
    # Daily at 18:15 UTC (no Monday special here)
    - cron: '15 18 * * *'

permissions:
  contents: write

concurrency:
  group: scrape-data
  cancel-in-progress: false

jobs:
  scrape:
    timeout-minutes: 120
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5.6.0
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run scraper
        env:
          PYTHONUNBUFFERED: "1"
          TELEGRAM_RSS_BASE: ${{ vars.TELEGRAM_RSS_BASE }}  # optional self-hosted RSSHub
        run: python scraper.py

      - name: Validate JSON Schema
        run: python validate.py

      - name: Quality checks (links, dates, dups)
        run: python qc_checks.py

      - name: Generate health.json
        run: |
          python - << 'PY'
          import json, datetime, pathlib
          data = json.loads(pathlib.Path("data.json").read_text(encoding="utf-8"))
          ti = data.get("transparencyInfo", {})
          health = {
            "ok": True,
            "checkedAt": datetime.datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ"),
            "lastUpdated": ti.get("lastUpdated"),
            "totalListings": ti.get("totalListings"),
            "aggCounts": ti.get("aggCounts"),
            "officialCounts": ti.get("officialCounts"),
            "telegramCounts": ti.get("telegramCounts"),
            "pendingFromTelegram": ti.get("pendingFromTelegram"),
          }
          pathlib.Path("health.json").write_text(json.dumps(health, ensure_ascii=False, indent=2), encoding="utf-8")
          PY

      - name: Format data.json
        run: |
          python - << 'PY'
          import json, pathlib
          p = pathlib.Path("data.json")
          p.write_text(json.dumps(json.loads(p.read_text(encoding="utf-8")), ensure_ascii=False, indent=2), encoding="utf-8")
          PY

      - name: Commit updated data.json and health.json if changed
        run: |
          git config user.name "actions-user"
          git config user.email "actions@users.noreply.github.com"
          CHANGED="$(git status --porcelain data.json health.json)"
          if [[ -n "$CHANGED" ]]; then
            git add data.json health.json
            git commit -m "chore(data): nightly refresh"
            git push
          else
            echo "No changes to commit."
          fi

  lighthouse:
    runs-on: ubuntu-latest
    needs: scrape
    if: ${{ vars.PAGES_URL != '' }}
    steps:
      - uses: actions/checkout@v4

      - name: Audit homepage with Lighthouse CI
        uses: treosh/lighthouse-ci-action@v12
        with:
          urls: |
            ${{ vars.PAGES_URL }}
          budgetPath: ./.github/lighthouse/budget.json
          uploadArtifacts: true

      - name: Check health.json exists (HTTP 200)
        run: |
          base="${{ vars.PAGES_URL }}"; base="${base%/}"
          url="$base/health.json"
          code=$(curl -s -o /dev/null -w "%{http_code}" "$url")
          if [ "$code" != "200" ]; then
            echo "health.json check failed with HTTP $code"; exit 1
          fi
          echo "health.json OK (HTTP $code)"
