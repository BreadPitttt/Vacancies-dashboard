name: Nightly Recheck

on:
  workflow_dispatch: {}
  schedule:
    - cron: '15 18 * * *'

permissions:
  contents: write

concurrency:
  group: scrape-data
  cancel-in-progress: false

jobs:
  scrape:
    timeout-minutes: 120
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python and cache dependencies
        uses: actions/setup-python@v5.6.0
        with:
          python-version: '3.11'
          cache: 'pip' # Cache pip dependencies

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip certifi cloudscraper
          pip install -r requirements.txt

      - name: Run scraper
        env:
          PYTHONUNBUFFERED: "1"
          TELEGRAM_RSS_BASE: ${{ vars.TELEGRAM_RSS_BASE }}
        run: python scraper.py

      - name: Validate JSON Schema
        run: python validate.py

      - name: Quality checks (links, dates, dups)
        run: python qc_checks.py

      - name: Generate health.json
        run: |
          python - << 'PY'
          import json, datetime, pathlib
          data = json.loads(pathlib.Path("data.json").read_text(encoding="utf-8"))
          ti = data.get("transparencyInfo", {})
          health = {"ok": True, "checkedAt": datetime.datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ"), **ti}
          pathlib.Path("health.json").write_text(json.dumps(health, ensure_ascii=False, indent=2), encoding="utf-8")
          PY

      - name: Format data.json
        run: |
          python - << 'PY'
          import json, pathlib
          p = pathlib.Path("data.json")
          p.write_text(json.dumps(json.loads(p.read_text(encoding="utf-8")), ensure_ascii=False, indent=2), encoding="utf-8")
          PY

      - name: Commit updated data.json and health.json if changed (rebase-safe)
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config user.name "actions-user"
          git config user.email "actions@users.noreply.github.com"
          if ! git diff --quiet -- data.json health.json; then
            git add data.json health.json
            git commit -m "chore(data): nightly refresh"
            git fetch origin main
            git pull --rebase origin main
            git push origin HEAD:main
          else
            echo "No changes to commit."
          fi

  lighthouse:
    runs-on: ubuntu-latest
    needs: scrape
    if: ${{ vars.PAGES_URL != '' }}
    steps:
      - uses: actions/checkout@v4
      - name: Audit homepage with Lighthouse CI
        uses: treosh/lighthouse-ci-action@v12
        with:
          urls: |
            ${{ vars.PAGES_URL }}
          budgetPath: ./.github/lighthouse/budget.json
          uploadArtifacts: true
      - name: Check health.json exists (HTTP 200)
        run: |
          base="${{ vars.PAGES_URL }}"; base="${base%/}"
          url="$base/health.json"
          code=$(curl -s -o /dev/null -w "%{http_code}" "$url")
          if [ "$code" != "200" ]; then
            echo "health.json check failed with HTTP $code"; exit 1
          fi
          echo "health.json OK (HTTP $code)"
